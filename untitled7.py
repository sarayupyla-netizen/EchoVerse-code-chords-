# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JtKuOfJ226CbIxdPUWYbwEKshMjYUpT4
"""

pip install gradio transformers torch gtts accelerate sentencepiece protobuf

import gradio as gr
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from gtts import gTTS
import os
import tempfile
from datetime import datetime

# Global variables for model
model = None
tokenizer = None
model_loaded = False

def load_granite_model(hf_token, progress=gr.Progress()):
    """Load IBM Granite 3.3-2B Instruct model from Hugging Face"""
    global model, tokenizer, model_loaded

    try:
        progress(0, desc="Starting model download...")
        model_name = "ibm-granite/granite-3.3-2b-instruct"

        progress(0.3, desc="Loading tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            use_auth_token=hf_token,
            trust_remote_code=True
        )

        progress(0.6, desc="Loading model (this may take several minutes)...")
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            use_auth_token=hf_token,
            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,
            device_map="auto",
            trust_remote_code=True
        )

        model_loaded = True
        progress(1.0, desc="Model loaded successfully!")

        return "âœ… Model loaded successfully! You can now generate audiobooks."

    except Exception as e:
        model_loaded = False
        return f"âŒ Error loading model: {str(e)}\n\nPlease check your Hugging Face token and internet connection."

def rewrite_text_with_tone(text, tone, progress=gr.Progress()):
    """Rewrite text with specified tone using IBM Granite model"""
    global model, tokenizer, model_loaded

    if not model_loaded:
        return "âŒ Please load the model first!", None, None

    if not text.strip():
        return "âŒ Please enter some text to rewrite!", None, None

    tone_instructions = {
        "Neutral": "Rewrite the following text in a clear, objective, and neutral tone. Keep all facts and information while removing emotional language. Make it professional and informative.",
        "Suspenseful": "Rewrite the following text to create suspense and tension. Use dramatic language, build anticipation, create mystery, and add excitement while keeping the core message intact. Make the reader feel engaged and curious about what happens next.",
        "Inspiring": "Rewrite the following text in an inspiring and motivational tone. Use uplifting language, emphasize positive aspects, encourage the reader, and create enthusiasm while maintaining the original meaning. Make it empowering and energizing."
    }

    prompt = f"""{tone_instructions[tone]}

Original Text:
{text}

Rewritten Text:"""

    try:
        progress(0.2, desc=f"Rewriting text with {tone} tone...")

        inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=2048)
        if torch.cuda.is_available():
            inputs = inputs.to('cuda')

        progress(0.5, desc="Generating rewritten text...")

        with torch.no_grad():
            outputs = model.generate(
                inputs.input_ids,
                max_new_tokens=1024,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )

        progress(0.8, desc="Processing output...")

        response = tokenizer.decode(outputs[0], skip_special_tokens=True)

        # Extract only the rewritten part
        if "Rewritten Text:" in response:
            rewritten = response.split("Rewritten Text:")[-1].strip()
        else:
            parts = response.split(text)
            rewritten = parts[-1].strip() if len(parts) > 1 else response.strip()

        if not rewritten or len(rewritten) < 10:
            rewritten = text  # fallback

        progress(1.0, desc="Text rewriting complete!")

        return f"âœ… Text rewritten successfully with {tone} tone!", rewritten, rewritten

    except Exception as e:
        return f"âŒ Error during text rewriting: {str(e)}", None, None

def generate_audio(rewritten_text, voice_choice, progress=gr.Progress()):
    """Convert text to speech using gTTS"""

    if not rewritten_text or not rewritten_text.strip():
        return "âŒ No text to convert to audio!", None

    try:
        progress(0.2, desc=f"Generating audio with {voice_choice} voice...")

        # Map voice choices to language/accent codes
        voice_map = {
            "Lisa (US Female)": ("en", "com"),
            "Michael (US Male)": ("en", "com"),
            "Allison (UK Female)": ("en", "co.uk"),
            "Emily (Australian Female)": ("en", "com.au"),
            "James (Canadian Male)": ("en", "ca")
        }

        lang, tld = voice_map.get(voice_choice, ("en", "com"))

        progress(0.5, desc="Processing speech synthesis...")

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        tts = gTTS(text=rewritten_text, lang=lang, tld=tld, slow=False)
        tts.save(temp_file.name)

        progress(1.0, desc="Audio generation complete!")

        return f"âœ… Audio generated successfully with {voice_choice} voice!", temp_file.name

    except Exception as e:
        return f"âŒ Error generating audio: {str(e)}", None

def process_audiobook(input_text, tone, voice_choice):
    """Complete audiobook generation pipeline"""

    if not model_loaded:
        return {
            "status_text": "âŒ Please load the model first using the Configuration tab!",
            "rewritten_output": None,
            "comparison_original": None,
            "comparison_rewritten": None,
            "audio_output": None,
            "audio_status": None
        }

    rewrite_status, rewritten_text, _ = rewrite_text_with_tone(input_text, tone)

    if rewritten_text is None:
        return {
            "status_text": rewrite_status,
            "rewritten_output": None,
            "comparison_original": None,
            "comparison_rewritten": None,
            "audio_output": None,
            "audio_status": None
        }

    audio_status, audio_path = generate_audio(rewritten_text, voice_choice)

    return {
        "status_text": rewrite_status,
        "rewritten_output": rewritten_text,
        "comparison_original": input_text,
        "comparison_rewritten": rewritten_text,
        "audio_output": audio_path,
        "audio_status": audio_status
    }

# Gradio interface
with gr.Blocks(theme=gr.themes.Soft(), title="AI Audiobook Creator") as demo:

    gr.Markdown("# ðŸŽ™ï¸ AI Audiobook Creator\n### Transform your text into professional audiobooks with AI-powered tone adaptation")

    with gr.Tabs() as tabs:

        # Configuration Tab
        with gr.Tab("âš™ï¸ Configuration"):
            gr.Markdown("### Model: IBM Granite 3.3-2B Instruct")
            hf_token_input = gr.Textbox(label="ðŸ”‘ Hugging Face Access Token", type="password", placeholder="Enter your HF token here")
            load_btn = gr.Button("ðŸš€ Load Model", variant="primary")
            model_status = gr.Textbox(label="Status", interactive=False, lines=3)

            load_btn.click(load_granite_model, inputs=[hf_token_input], outputs=[model_status])

        # Generation Tab
        with gr.Tab("ðŸŽ¬ Generate Audiobook"):
            input_text = gr.Textbox(label="Input Text", lines=12, placeholder="Enter the text you want to convert into an audiobook...")

            with gr.Row():
                tone_choice = gr.Radio(
                    choices=["Neutral", "Suspenseful", "Inspiring"],
                    value="Neutral",
                    label="ðŸŽ­ Tone"
                )
                voice_choice = gr.Radio(
                    choices=["Lisa (US Female)", "Michael (US Male)", "Allison (UK Female)", "Emily (Australian Female)", "James (Canadian Male)"],
                    value="Lisa (US Female)",
                    label="ðŸŽ¤ Voice"
                )

            generate_btn = gr.Button("ðŸŽ¬ Generate Audiobook", variant="primary", size="lg")

            status_text = gr.Textbox(label="Generation Status", interactive=False)

            with gr.Accordion("ðŸ“ Tone-Adapted Text", open=True):
                rewritten_output = gr.Textbox(label="Rewritten Text", lines=12, interactive=False)

            with gr.Accordion("ðŸ” Comparison View", open=False):
                with gr.Row():
                    comparison_original = gr.Textbox(label="Original Text", lines=8, interactive=False)
                    comparison_rewritten = gr.Textbox(label="Rewritten Text", lines=8, interactive=False)

            audio_status = gr.Textbox(label="Audio Status", interactive=False)
            audio_output = gr.Audio(label="ðŸŽ§ Generated Audiobook", type="filepath")

            generate_btn.click(
                fn=process_audiobook,
                inputs=[input_text, tone_choice, voice_choice],
                outputs=[status_text, rewritten_output, comparison_original, comparison_rewritten, audio_output, audio_status]
            )

if __name__ == "__main__":
    demo.launch(share=False, show_error=True)